
# # print(y)


# try:
#     x = 1/0
#     print(x)
#     print(y)
# except ZeroDivisionError:
#     print("zero devision error")
# except NameError:
#     print("y is not defined")

num1 = int(input("enter the value of string"))
num2 = int(input("enter the value of integer"))
final_num = num1 + num2
print(final_num)

